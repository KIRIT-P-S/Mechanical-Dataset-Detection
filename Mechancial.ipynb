{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65fee385-ccc6-4efa-80cc-a100fd8aa35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix)\n",
    "import seaborn as sns\n",
    "import timm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c9b709-e83a-47f3-9b06-d3436a2c1849",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVTecMultiClassDataset(Dataset):\n",
    "    def __init__(self, root_dir, categories, split='train', transform=None):\n",
    "        self.root_dir = root_dir \n",
    "        self.categories = categories\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.category_to_idx = {cat: idx for idx, cat in enumerate(categories)}\n",
    "        self.num_classes = len(categories)\n",
    "        \n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for category in categories:\n",
    "            category_path = os.path.join(root_dir, category, split)\n",
    "            \n",
    "            if split == 'train':\n",
    "                good_path = os.path.join(category_path, 'good')\n",
    "                if os.path.exists(good_path):\n",
    "                    for img_name in os.listdir(good_path):\n",
    "                        if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                            self.image_paths.append(os.path.join(good_path, img_name))\n",
    "                            self.labels.append(self.category_to_idx[category])\n",
    "            else:\n",
    "                if os.path.exists(category_path):\n",
    "                    for defect_type in os.listdir(category_path):\n",
    "                        defect_path = os.path.join(category_path, defect_type)\n",
    "                        if os.path.isdir(defect_path):\n",
    "                            for img_name in os.listdir(defect_path):\n",
    "                                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                                    self.image_paths.append(os.path.join(defect_path, img_name))\n",
    "                                    self.labels.append(self.category_to_idx[category])\n",
    "        \n",
    "        print(f\"Loaded {len(self.image_paths)} images for {split} split\")\n",
    "        print(f\"Categories: {self.categories}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "            label = self.labels[idx]\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {self.image_paths[idx]}: {e}\")\n",
    "            dummy_image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "            if self.transform:\n",
    "                dummy_image = self.transform(dummy_image)\n",
    "            return dummy_image, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50a89cb7-8631-4cb3-8db3-929c6eae695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c5d759-4f06-4b16-a2fc-5089eea93b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['bottle', 'cable', 'capsule', 'carpet', 'grid', \n",
    "              'hazelnut', 'leather', 'metal_nut', 'pill', 'screw',\n",
    "              'tile', 'toothbrush', 'transistor', 'wood', 'zipper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f06f0d04-c129-4f41-8ce9-fdb3658725cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3838 images for train split\n",
      "Categories: ['bottle', 'cable', 'capsule', 'carpet', 'grid', 'hazelnut', 'leather', 'metal_nut', 'pill', 'screw', 'tile', 'toothbrush', 'transistor', 'wood', 'zipper']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MVTecMultiClassDataset(\n",
    "    root_dir='mvtec_anomaly_detection',\n",
    "    categories=categories,\n",
    "    split='train',\n",
    "    transform=transform_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21e453b-42ca-4edf-85c4-cb275272283a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1725 images for test split\n",
      "Categories: ['bottle', 'cable', 'capsule', 'carpet', 'grid', 'hazelnut', 'leather', 'metal_nut', 'pill', 'screw', 'tile', 'toothbrush', 'transistor', 'wood', 'zipper']\n"
     ]
    }
   ],
   "source": [
    "test_dataset = MVTecMultiClassDataset(\n",
    "    root_dir='mvtec_anomaly_detection',\n",
    "    categories=categories,\n",
    "    split='test',\n",
    "    transform=transform_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43e5956c-b2c3-40f9-853f-af01d2ca53f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e896fe30-c791-490f-958b-526b4ca76d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dcd968d-582f-4674-a806-6b141bf2a69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 3838\n",
      "Testing samples: 1725\n",
      "Number of classes: 15\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")\n",
    "print(f\"Number of classes: {len(categories)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ec2989f-cb3b-404f-b022-86385851e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(dataset, dataset_name):\n",
    "    print(f\"\\n=== {dataset_name} Analysis ===\")\n",
    "    print(f\"Total samples: {len(dataset)}\")\n",
    "    \n",
    "    label_counts = {}\n",
    "    for _, label in dataset:\n",
    "        if label in label_counts:\n",
    "            label_counts[label] += 1\n",
    "        else:\n",
    "            label_counts[label] = 1\n",
    "    \n",
    "    print(\"Samples per category:\")\n",
    "    for cat_idx, cat_name in enumerate(dataset.categories):\n",
    "        count = label_counts.get(cat_idx, 0)\n",
    "        print(f\"  {cat_name} (class {cat_idx}): {count} samples\")\n",
    "    \n",
    "    if len(dataset) > 0:\n",
    "        sample_image, sample_label = dataset[0]\n",
    "        print(f\"Sample image shape: {sample_image.shape}\")\n",
    "        print(f\"Sample label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c653657b-cf28-4acc-9718-1a648ac7cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_dataset(train_dataset, \"Training Dataset\")\n",
    "# analyze_dataset(test_dataset, \"Test Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0642a844-5808-412a-bbb6-e68f6b5e70fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Output shape: torch.Size([1, 15])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=15):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  \n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = F.dropout(F.relu(self.fc1(x)), p=0.3, training=self.training)  \n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = SimpleCNN(num_classes=15).to(device)\n",
    "\n",
    "dummy = torch.randn(1, 3, 224, 224).to(device)\n",
    "print(\"Output shape:\", model(dummy).shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c16291-34d0-4bba-b863-b6e90b7dd814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, device, epochs=10, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        batch_count = len(train_loader)\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if (batch_idx + 1) % 20 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Batch [{batch_idx+1}/{batch_count}], \"\n",
    "                      f\"Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        train_acc = 100 * correct / total\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        \n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_acc = 100 * test_correct / test_total\n",
    "        print(f\"Test Acc: {test_acc:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b0c055-83c5-46db-8306-c191ccc213aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, roc_auc_score, classification_report, \n",
    "                           confusion_matrix)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def calculate_all_metrics(y_true, y_pred, y_probs, num_classes):\n",
    "    \"\"\"\n",
    "    Calculate all metrics mentioned in the abstract\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    try:\n",
    "        if len(np.unique(y_true)) > 2: \n",
    "            auc_roc = roc_auc_score(y_true, y_probs, multi_class='ovr', average='weighted')\n",
    "        else: \n",
    "            auc_roc = roc_auc_score(y_true, y_probs[:, 1])\n",
    "    except:\n",
    "        auc_roc = 0.0\n",
    "    \n",
    "    precision_per_class = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    recall_per_class = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc_roc': auc_roc,\n",
    "        'precision_per_class': precision_per_class,\n",
    "        'recall_per_class': recall_per_class,\n",
    "        'f1_per_class': f1_per_class\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, data_loader, device, categories):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation with all metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    metrics = calculate_all_metrics(all_labels, all_preds, all_probs, len(categories))\n",
    "    \n",
    "    return metrics, all_labels, all_preds, all_probs\n",
    "\n",
    "def print_detailed_metrics(metrics, categories):\n",
    "    \"\"\"\n",
    "    Print detailed metrics report\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"COMPREHENSIVE EVALUATION METRICS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\n📊 OVERALL PERFORMANCE:\")\n",
    "    print(f\"   Accuracy:  {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\")\n",
    "    print(f\"   Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {metrics['f1_score']:.4f}\")\n",
    "    print(f\"   AUC-ROC:   {metrics['auc_roc']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n📈 PER-CLASS PERFORMANCE:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Category':<15} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, category in enumerate(categories):\n",
    "        if i < len(metrics['precision_per_class']):\n",
    "            print(f\"{category:<15} {metrics['precision_per_class'][i]:.4f}     \"\n",
    "                  f\"{metrics['recall_per_class'][i]:.4f}     \"\n",
    "                  f\"{metrics['f1_per_class'][i]:.4f}\")\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, categories, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=categories, yticklabels=categories)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def train_model_with_metrics(model, train_loader, test_loader, device, categories, \n",
    "                           epochs=15, lr=0.001):\n",
    "    \"\"\"\n",
    "    Enhanced training function with comprehensive metrics tracking\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_metrics_history = []\n",
    "    test_metrics_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_labels = []\n",
    "        train_preds = []\n",
    "        train_probs = []\n",
    "        \n",
    "        print(f\"\\n🚀 Epoch [{epoch+1}/{epochs}]\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_probs.extend(probs.cpu().detach().numpy())\n",
    "            \n",
    "            if (batch_idx + 1) % 20 == 0:\n",
    "                print(f\"   Batch [{batch_idx+1}/{len(train_loader)}] - Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        train_metrics = calculate_all_metrics(\n",
    "            np.array(train_labels), np.array(train_preds), \n",
    "            np.array(train_probs), len(categories)\n",
    "        )\n",
    "        train_metrics_history.append(train_metrics)\n",
    "        \n",
    "        test_metrics, test_labels, test_preds, test_probs = evaluate_model(\n",
    "            model, test_loader, device, categories\n",
    "        )\n",
    "        test_metrics_history.append(test_metrics)\n",
    "        \n",
    "        print(f\"\\n📈 EPOCH {epoch+1} RESULTS:\")\n",
    "        print(f\"   Train - Acc: {train_metrics['accuracy']*100:.2f}% | \"\n",
    "              f\"F1: {train_metrics['f1_score']:.4f} | \"\n",
    "              f\"AUC: {train_metrics['auc_roc']:.4f}\")\n",
    "        print(f\"   Test  - Acc: {test_metrics['accuracy']*100:.2f}% | \"\n",
    "              f\"F1: {test_metrics['f1_score']:.4f} | \"\n",
    "              f\"AUC: {test_metrics['auc_roc']:.4f}\")\n",
    "        \n",
    "        if epoch > 0 and test_metrics['f1_score'] < test_metrics_history[-2]['f1_score']:\n",
    "            print(\"   ⚠️  F1-score decreased, consider early stopping\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL MODEL EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    final_metrics, final_labels, final_preds, final_probs = evaluate_model(\n",
    "        model, test_loader, device, categories\n",
    "    )\n",
    "    \n",
    "    print_detailed_metrics(final_metrics, categories)\n",
    "    \n",
    "    print(\"\\n📋 DETAILED CLASSIFICATION REPORT:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(classification_report(final_labels, final_preds, target_names=categories))\n",
    "    \n",
    "    plot_confusion_matrix(final_labels, final_preds, categories)\n",
    "    \n",
    "    return {\n",
    "        'train_history': train_metrics_history,\n",
    "        'test_history': test_metrics_history,\n",
    "        'final_metrics': final_metrics,\n",
    "        'final_predictions': (final_labels, final_preds, final_probs)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bc7b140-7ff2-4e2f-a7b6-1a6e9f5c92f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/5], Batch [20/120], Loss: 8.5908\n",
      "Epoch [1/5], Batch [40/120], Loss: 3.5644\n",
      "Epoch [1/5], Batch [60/120], Loss: 0.0678\n",
      "Epoch [1/5], Batch [80/120], Loss: 0.3678\n",
      "Epoch [1/5], Batch [100/120], Loss: 0.0107\n",
      "Epoch [1/5], Batch [120/120], Loss: 0.0000\n",
      "Epoch [1/5] - Loss: 4.9258 | Train Acc: 87.00%\n",
      "Test Acc: 99.07%\n",
      "\n",
      "Epoch [2/5], Batch [20/120], Loss: 0.0549\n",
      "Epoch [2/5], Batch [40/120], Loss: 0.0025\n",
      "Epoch [2/5], Batch [60/120], Loss: 0.0066\n",
      "Epoch [2/5], Batch [80/120], Loss: 0.0000\n",
      "Epoch [2/5], Batch [100/120], Loss: 0.0387\n",
      "Epoch [2/5], Batch [120/120], Loss: 0.0000\n",
      "Epoch [2/5] - Loss: 0.1339 | Train Acc: 97.71%\n",
      "Test Acc: 99.88%\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m SimpleCNN(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 15\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, test_loader, device, epochs, lr)\u001b[0m\n\u001b[0;32m     12\u001b[0m batch_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m---> 15\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     18\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = SimpleCNN(num_classes=15).to(device)\n",
    "train_model(model, train_loader, test_loader, device, epochs=5, lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04bf602-7bf7-4b6d-aa97-ac5a986a75e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = train_model_with_metrics(\n",
    "    model, train_loader, test_loader, device, categories, \n",
    "    epochs=3, lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23bb2f83-7c1f-45b1-96d7-0eee6163265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade3af3-97db-4eab-8cc5-c33e24885081",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNFeatureExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self, output_dim=768):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            \n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 3\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 4\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((14, 14))  # 14x14 = 196 patches\n",
    "        \n",
    "        self.feature_projection = nn.Linear(512, output_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.conv_blocks(x)  # [B, 512, H, W]\n",
    "        \n",
    "        features = self.adaptive_pool(features)  # [B, 512, 14, 14]\n",
    "        \n",
    "        B, C, H, W = features.shape\n",
    "        features = features.view(B, C, H * W).transpose(1, 2)  # [B, 196, 512]\n",
    "        \n",
    "        features = self.feature_projection(features)  # [B, 196, 768]\n",
    "        features = self.dropout(features)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d514745-8279-462d-b9fa-1ac1eb7468f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNDeiTModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=15, embed_dim=768, num_heads=12, num_layers=12):\n",
    "        super(CNNDeiTModel, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        self.cnn_extractor = CNNFeatureExtractor(output_dim=embed_dim)\n",
    "        \n",
    "        self.deit_model = timm.create_model(\n",
    "            'deit_base_patch16_224',\n",
    "            pretrained=True,\n",
    "            num_classes=0,  \n",
    "            img_size=224\n",
    "        )\n",
    "        \n",
    "        self.transformer_blocks = self.deit_model.blocks\n",
    "        self.norm = self.deit_model.norm\n",
    "        \n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, 197, embed_dim))\n",
    "        \n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(embed_dim // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.dist_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        \n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize model weights\"\"\"\n",
    "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
    "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "        nn.init.trunc_normal_(self.dist_token, std=0.02)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        \n",
    "        cnn_features = self.cnn_extractor(x)  # [B, 196, 768]\n",
    "        \n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # [B, 1, 768]\n",
    "        dist_tokens = self.dist_token.expand(B, -1, -1)  # [B, 1, 768]\n",
    "        \n",
    "        x = torch.cat([cls_tokens, dist_tokens, cnn_features], dim=1)  # [B, 198, 768]\n",
    "        \n",
    "        pos_embed = torch.cat([\n",
    "            self.pos_embed[:, :1, :],  # CLS token position\n",
    "            self.pos_embed[:, :1, :],  # Distillation token position (reuse CLS)\n",
    "            self.pos_embed[:, 1:, :]   # Patch positions\n",
    "        ], dim=1)\n",
    "        \n",
    "        x = x + pos_embed[:, :x.size(1), :]\n",
    "        \n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        \n",
    "        cls_output = x[:, 0]  # [B, 768]\n",
    "        \n",
    "        output = self.classifier(cls_output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee878e84-a074-404c-a8c2-bb324f09ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_deit_model(num_classes=15, pretrained=True):\n",
    "\n",
    "    model = CNNDeiTModel(num_classes=num_classes)\n",
    "    \n",
    "    if pretrained:\n",
    "        print(\"Using pre-trained DeiT weights\")\n",
    "    else:\n",
    "        print(\"Training from scratch\")\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e62d9-9d16-4ad4-b981-f66a77d7bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn_deit_model(model, train_loader, test_loader, device, categories, \n",
    "                        epochs=20, lr=1e-4, weight_decay=1e-4):\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), \n",
    "                           lr=lr, \n",
    "                           weight_decay=weight_decay,\n",
    "                           betas=(0.9, 0.999))\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    \n",
    "    train_metrics_history = []\n",
    "    test_metrics_history = []\n",
    "    best_f1 = 0.0\n",
    "    \n",
    "    print(f\"Starting CNN+DeiT Training\")\n",
    "    print(f\"Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"Trainable Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_labels = []\n",
    "        train_preds = []\n",
    "        train_probs = []\n",
    "        \n",
    "        print(f\"\\nEpoch [{epoch+1}/{epochs}] - LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_probs.extend(probs.cpu().detach().numpy())\n",
    "            \n",
    "            if (batch_idx + 1) % 20 == 0:\n",
    "                print(f\"   Batch [{batch_idx+1}/{len(train_loader)}] - Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        train_metrics = calculate_all_metrics(\n",
    "            np.array(train_labels), np.array(train_preds), \n",
    "            np.array(train_probs), len(categories)\n",
    "        )\n",
    "        train_metrics_history.append(train_metrics)\n",
    "        \n",
    "        test_metrics, test_labels, test_preds, test_probs = evaluate_model(\n",
    "            model, test_loader, device, categories\n",
    "        )\n",
    "        test_metrics_history.append(test_metrics)\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"\\n EPOCH {epoch+1} RESULTS:\")\n",
    "        print(f\"   Loss: {avg_loss:.4f}\")\n",
    "        print(f\"   Train - Acc: {train_metrics['accuracy']*100:.2f}% | \"\n",
    "              f\"Precision: {train_metrics['precision']:.4f} | \"\n",
    "              f\"Recall: {train_metrics['recall']:.4f} | \"\n",
    "              f\"F1: {train_metrics['f1_score']:.4f} | \"\n",
    "              f\"AUC: {train_metrics['auc_roc']:.4f}\")\n",
    "        print(f\"   Test  - Acc: {test_metrics['accuracy']*100:.2f}% | \"\n",
    "              f\"Precision: {test_metrics['precision']:.4f} | \"\n",
    "              f\"Recall: {test_metrics['recall']:.4f} | \"\n",
    "              f\"F1: {test_metrics['f1_score']:.4f} | \"\n",
    "              f\"AUC: {test_metrics['auc_roc']:.4f}\")\n",
    "        \n",
    "        if test_metrics['f1_score'] > best_f1:\n",
    "            best_f1 = test_metrics['f1_score']\n",
    "            torch.save(model.state_dict(), 'best_cnn_deit_model.pth')\n",
    "            print(f\"   New best model saved! F1-Score: {best_f1:.4f}\")\n",
    "    \n",
    "    model.load_state_dict(torch.load('best_cnn_deit_model.pth'))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL CNN+DeiT MODEL EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    final_metrics, final_labels, final_preds, final_probs = evaluate_model(\n",
    "        model, test_loader, device, categories\n",
    "    )\n",
    "    \n",
    "    print_detailed_metrics(final_metrics, categories)\n",
    "    \n",
    "    print(\"\\n DETAILED CLASSIFICATION REPORT:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(classification_report(final_labels, final_preds, target_names=categories))\n",
    "    \n",
    "    plot_confusion_matrix(final_labels, final_preds, categories, \n",
    "                         save_path='cnn_deit_confusion_matrix.png')\n",
    "    \n",
    "    return {\n",
    "        'train_history': train_metrics_history,\n",
    "        'test_history': test_metrics_history,\n",
    "        'final_metrics': final_metrics,\n",
    "        'final_predictions': (final_labels, final_preds, final_probs),\n",
    "        'best_f1_score': best_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c61debbb-eb53-496f-8ce3-db42b2cb9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(cnn_results, cnn_deit_results):\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" MODEL COMPARISON: CNN vs CNN+DeiT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    cnn_metrics = cnn_results['final_metrics']\n",
    "    deit_metrics = cnn_deit_results['final_metrics']\n",
    "    \n",
    "    metrics_names = ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']\n",
    "    \n",
    "    print(f\"{'Metric':<15} {'CNN':<12} {'CNN+DeiT':<12} {'Improvement':<12}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for metric in metrics_names:\n",
    "        cnn_val = cnn_metrics[metric]\n",
    "        deit_val = deit_metrics[metric]\n",
    "        improvement = ((deit_val - cnn_val) / cnn_val) * 100 if cnn_val > 0 else 0\n",
    "        \n",
    "        print(f\"{metric.upper():<15} {cnn_val:.4f}      {deit_val:.4f}      \"\n",
    "              f\"{improvement:+.2f}%\")\n",
    "    \n",
    "    print(\"\\n KEY IMPROVEMENTS:\")\n",
    "    for metric in metrics_names:\n",
    "        cnn_val = cnn_metrics[metric]\n",
    "        deit_val = deit_metrics[metric]\n",
    "        if deit_val > cnn_val:\n",
    "            improvement = ((deit_val - cnn_val) / cnn_val) * 100\n",
    "            print(f\"   {metric.upper()}: +{improvement:.2f}% improvement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162971a3-b722-4098-9aea-aecb8e5fde1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using pre-trained DeiT weights\n",
      "\n",
      " CNN+DeiT MODEL ARCHITECTURE:\n",
      "   Total Parameters: 91,306,383\n",
      "   Trainable Parameters: 91,306,383\n",
      "   Model Size: ~348.3 MB\n",
      "\n",
      " Starting CNN+DeiT Training...\n",
      "Starting CNN+DeiT Training\n",
      "Model Parameters: 91,306,383\n",
      "Trainable Parameters: 91,306,383\n",
      "\n",
      "Epoch [1/20] - LR: 0.000100\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "cnn_deit_model = create_cnn_deit_model(num_classes=15, pretrained=True)\n",
    "cnn_deit_model = cnn_deit_model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in cnn_deit_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in cnn_deit_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n CNN+DeiT MODEL ARCHITECTURE:\")\n",
    "print(f\"   Total Parameters: {total_params:,}\")\n",
    "print(f\"   Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"   Model Size: ~{total_params * 4 / (1024**2):.1f} MB\")\n",
    "\n",
    "print(\"\\n Starting CNN+DeiT Training...\")\n",
    "cnn_deit_results = train_cnn_deit_model(\n",
    "    cnn_deit_model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    device, \n",
    "    categories,\n",
    "    epochs=20, \n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "print(f\"\\n CNN+DeiT FINAL PERFORMANCE:\")\n",
    "final_metrics = cnn_deit_results['final_metrics']\n",
    "print(f\"   Accuracy:  {final_metrics['accuracy']*100:.2f}%\")\n",
    "print(f\"   Precision: {final_metrics['precision']:.4f}\")\n",
    "print(f\"   Recall:    {final_metrics['recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {final_metrics['f1_score']:.4f}\")\n",
    "print(f\"   AUC-ROC:   {final_metrics['auc_roc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6d21e-9395-4b9e-9f12-c5ac332052a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import timm\n",
    "\n",
    "\n",
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, rank=4, alpha=16, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "        self.scaling = alpha / rank\n",
    "        \n",
    "        self.lora_A = nn.Parameter(torch.randn(in_features, rank) / math.sqrt(rank))\n",
    "        self.lora_B = nn.Parameter(torch.zeros(rank, out_features))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        assert not torch.isnan(self.lora_A).any(), \"LoRA_A contains NaN\"\n",
    "        assert not torch.isnan(self.lora_B).any(), \"LoRA_B contains NaN\"\n",
    "\n",
    "\n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, original_layer, rank=4, alpha=16, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.original_layer = original_layer\n",
    "        self.lora = LoRALayer(\n",
    "            original_layer.in_features,\n",
    "            original_layer.out_features,\n",
    "            rank=rank, alpha=alpha, dropout=dropout\n",
    "        )\n",
    "        for param in self.original_layer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.original_layer(x) + self.lora(x)\n",
    "\n",
    "class LoRAConv2d(nn.Module):\n",
    "    def __init__(self, original_conv, rank=4, alpha=16, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.original_conv = original_conv\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "        self.scaling = alpha / rank\n",
    "\n",
    "        in_channels = original_conv.in_channels\n",
    "        out_channels = original_conv.out_channels\n",
    "        kernel_size = original_conv.kernel_size\n",
    "\n",
    "        # LoRA decomposition for conv: two 1x1 convs (A then B)\n",
    "        self.lora_A = nn.Conv2d(in_channels, rank, kernel_size=1, bias=False)\n",
    "        self.lora_B = nn.Conv2d(rank, out_channels, kernel_size=kernel_size,\n",
    "                                stride=original_conv.stride,\n",
    "                                padding=original_conv.padding,\n",
    "                                bias=False)\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.lora_A.weight, a=math.sqrt(5))\n",
    "        nn.init.zeros_(self.lora_B.weight)\n",
    "\n",
    "        self.dropout = nn.Dropout2d(dropout)\n",
    "\n",
    "        for param in self.original_conv.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        original_out = self.original_conv(x)\n",
    "        lora_out = self.lora_B(self.dropout(self.lora_A(x))) * self.scaling\n",
    "        return original_out + lora_out\n",
    "\n",
    "def validate_and_fix_parameters(model):\n",
    "    \"\"\"Validate and fix any parameter issues\"\"\"\n",
    "    print(\"Validating and fixing model parameters...\")\n",
    "    \n",
    "    fixed_count = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:  \n",
    "            if torch.isnan(param).any() or torch.isinf(param).any():\n",
    "                print(f\"Fixing invalid values in {name}\")\n",
    "                if 'weight' in name:\n",
    "                    if len(param.shape) >= 2:\n",
    "                        nn.init.xavier_uniform_(param)\n",
    "                    else:\n",
    "                        nn.init.uniform_(param, -0.1, 0.1)\n",
    "                elif 'bias' in name:\n",
    "                    nn.init.zeros_(param)\n",
    "                else:\n",
    "                    nn.init.normal_(param, 0, 0.01)\n",
    "                fixed_count += 1\n",
    "    \n",
    "    print(f\"Fixed {fixed_count} parameters\")\n",
    "    return model\n",
    "\n",
    "\n",
    "class CNNDeiTLoRAModel(nn.Module):\n",
    "    def __init__(self, num_classes, cnn_backbone='resnet50', deit_model='deit_small_patch16_224',\n",
    "                 lora_rank=4, lora_alpha=16, lora_dropout=0.1, freeze_cnn=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn_backbone = timm.create_model(cnn_backbone, pretrained=True, num_classes=0)\n",
    "        cnn_features = self.cnn_backbone.num_features\n",
    "\n",
    "        if not freeze_cnn:\n",
    "            self._apply_lora_to_cnn(lora_rank, lora_alpha, lora_dropout)\n",
    "        else:\n",
    "            for param in self.cnn_backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.deit = timm.create_model(deit_model, pretrained=True, num_classes=0)\n",
    "        deit_features = self.deit.num_features\n",
    "\n",
    "        self._apply_lora_to_deit(lora_rank, lora_alpha, lora_dropout)\n",
    "\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(cnn_features + deit_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _apply_lora_to_cnn(self, rank, alpha, dropout):\n",
    "        for name, module in list(self.cnn_backbone.named_modules()):\n",
    "            if isinstance(module, nn.Conv2d) and 'downsample' not in name:\n",
    "                parent_name = '.'.join(name.split('.')[:-1])\n",
    "                child_name = name.split('.')[-1]\n",
    "                if parent_name:\n",
    "                    parent = self.cnn_backbone.get_submodule(parent_name)\n",
    "                    setattr(parent, child_name, LoRAConv2d(module, rank, alpha, dropout))\n",
    "\n",
    "    def _apply_lora_to_deit(self, rank, alpha, dropout):\n",
    "        for name, module in list(self.deit.named_modules()):\n",
    "            if isinstance(module, nn.Linear) and ('qkv' in name or 'proj' in name or 'fc' in name):\n",
    "                parent_name = '.'.join(name.split('.')[:-1])\n",
    "                child_name = name.split('.')[-1]\n",
    "                if parent_name:\n",
    "                    parent = self.deit.get_submodule(parent_name)\n",
    "                    setattr(parent, child_name, LoRALinear(module, rank, alpha, dropout))\n",
    "\n",
    "    def forward(self, x):\n",
    "        cnn_features = self.cnn_backbone(x)  \n",
    "        deit_features = self.deit(x)          \n",
    "        combined_features = torch.cat([cnn_features, deit_features], dim=1)\n",
    "        fused_features = self.fusion_layer(combined_features)\n",
    "        output = self.classifier(fused_features)\n",
    "        return output\n",
    "\n",
    "    def count_parameters(self):\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        return total_params, trainable_params\n",
    "\n",
    "\n",
    "def safe_move_model_to_device(model, device):\n",
    "    \"\"\"Enhanced model device transfer with parameter validation\"\"\"\n",
    "    print(f\"Attempting to move model to {device}...\")\n",
    "    \n",
    "    print(\"Validating parameters before GPU transfer...\")\n",
    "    invalid_params = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        try:\n",
    "            if torch.isnan(param).any():\n",
    "                invalid_params.append(f\"{name}: contains NaN\")\n",
    "            if torch.isinf(param).any():\n",
    "                invalid_params.append(f\"{name}: contains Inf\")\n",
    "            \n",
    "            param_abs_max = param.abs().max().item()\n",
    "            if param_abs_max > 1e6:\n",
    "                invalid_params.append(f\"{name}: unusually large values (max: {param_abs_max})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            invalid_params.append(f\"{name}: validation error - {e}\")\n",
    "    \n",
    "    if invalid_params:\n",
    "        print(\"INVALID PARAMETERS DETECTED:\")\n",
    "        for issue in invalid_params[:10]: \n",
    "            print(f\"  - {issue}\")\n",
    "        print(\"Fix these issues before moving to GPU!\")\n",
    "        return model\n",
    "    \n",
    "    try:\n",
    "        print(\"Moving CNN backbone...\")\n",
    "        model.cnn_backbone.to(device)\n",
    "        \n",
    "        print(\"Moving DeiT transformer...\")\n",
    "        model.deit.to(device)\n",
    "        \n",
    "        print(\"Moving fusion layers...\")\n",
    "        model.fusion_layer.to(device)\n",
    "        \n",
    "        print(\"Moving classifier...\")\n",
    "        model.classifier.to(device)\n",
    "        \n",
    "        print(f\"✓ Model successfully moved to {device}\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during model.to(device): {e}\")\n",
    "        \n",
    "        print(\"Resetting model to CPU...\")\n",
    "        model.cpu()\n",
    "        \n",
    "        print(\"\\nCUDA Memory Info:\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"  Allocated: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "            print(f\"  Reserved: {torch.cuda.memory_reserved()/1e9:.2f} GB\")\n",
    "            print(f\"  Max allocated: {torch.cuda.max_memory_allocated()/1e9:.2f} GB\")\n",
    "        \n",
    "        raise\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "def calculate_all_metrics(y_true, y_pred, y_probs, num_classes):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    if num_classes > 2:\n",
    "        auc = roc_auc_score(y_true, y_probs, multi_class='ovr', average='weighted')\n",
    "    else:\n",
    "        auc = roc_auc_score(y_true, y_probs[:, 1])\n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1_score': f1, 'auc_roc': auc}\n",
    "\n",
    "def evaluate_model(model, test_loader, device, categories):\n",
    "    model.eval()\n",
    "    test_labels, test_preds, test_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "            test_preds.extend(preds.cpu().numpy())\n",
    "            test_probs.extend(probs.cpu().numpy())\n",
    "    test_labels = np.array(test_labels)\n",
    "    test_preds = np.array(test_preds)\n",
    "    test_probs = np.array(test_probs)\n",
    "    metrics = calculate_all_metrics(test_labels, test_preds, test_probs, len(categories))\n",
    "    return metrics, test_labels, test_preds, test_probs\n",
    "\n",
    "\n",
    "def train_cnn_deit_lora_model(\n",
    "    model, train_loader, test_loader, device, categories,\n",
    "    epochs=20, lr=1e-4, weight_decay=1e-4\n",
    "):\n",
    "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    train_metrics_history, test_metrics_history = [], []\n",
    "\n",
    "    num_classes = len(categories)\n",
    "    print(\"Before training, classifier shape:\", getattr(model, \"classifier\").weight.shape, \"num_classes:\", num_classes)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_labels, train_preds, train_probs = [], [], []\n",
    "\n",
    "        print(f\"\\nEpoch [{epoch+1}/{epochs}] - LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            if labels.dtype != torch.long:\n",
    "                labels = labels.long()\n",
    "\n",
    "            try:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)  # [B, C]\n",
    "\n",
    "                if batch_idx < 3:\n",
    "                    print(f\"Batch {batch_idx} -> outputs.shape={outputs.shape}, labels.shape={labels.shape}\")\n",
    "                    print(f\"   labels min={labels.min().item()} max={labels.max().item()} (num_classes={num_classes})\")\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                train_labels.extend(labels.cpu().numpy())\n",
    "                train_preds.extend(preds.cpu().numpy())\n",
    "                train_probs.extend(probs.cpu().detach().numpy())\n",
    "\n",
    "                if (batch_idx + 1) % 20 == 0:\n",
    "                    print(f\"   Batch [{batch_idx+1}/{len(train_loader)}] - Loss: {loss.item():.4f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"\\nError in batch\", batch_idx, \"-> Exception:\", repr(e))\n",
    "                if 'outputs' in locals():\n",
    "                    print(\"outputs.shape:\", outputs.shape)\n",
    "                print(\"labels dtype/device/min/max/unique:\")\n",
    "                try:\n",
    "                    print(labels.dtype, labels.device, labels.min().item(), labels.max().item(), torch.unique(labels))\n",
    "                except Exception:\n",
    "                    print(\"Could not print labels details.\")\n",
    "                raise\n",
    "\n",
    "        scheduler.step()\n",
    "        train_metrics = calculate_all_metrics(np.array(train_labels), np.array(train_preds), np.array(train_probs), num_classes)\n",
    "        train_metrics_history.append(train_metrics)\n",
    "\n",
    "        test_metrics, _, _, _ = evaluate_model(model, test_loader, device, categories)\n",
    "        test_metrics_history.append(test_metrics)\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"\\n EPOCH {epoch+1} RESULTS:\")\n",
    "        print(f\"   Loss: {avg_loss:.4f}\")\n",
    "        print(f\"   Train - Acc: {train_metrics['accuracy']*100:.2f}% | F1: {train_metrics['f1_score']:.4f} | AUC: {train_metrics['auc_roc']:.4f}\")\n",
    "        print(f\"   Test  - Acc: {test_metrics['accuracy']*100:.2f}% | F1: {test_metrics['f1_score']:.4f} | AUC: {test_metrics['auc_roc']:.4f}\")\n",
    "\n",
    "        if test_metrics['f1_score'] > best_f1:\n",
    "            best_f1 = test_metrics['f1_score']\n",
    "            torch.save(model.state_dict(), 'best_cnn_deit_lora_model_debug.pth')\n",
    "            print(\"Saved new best model:\", best_f1)\n",
    "\n",
    "    return {\n",
    "        'train_history': train_metrics_history,\n",
    "        'test_history': test_metrics_history,\n",
    "        'best_f1_score': best_f1\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Creating model...\")\n",
    "    num_classes = 10\n",
    "    categories = [f'class_{i}' for i in range(num_classes)]\n",
    "    \n",
    "    model = CNNDeiTLoRAModel(\n",
    "        num_classes=num_classes,\n",
    "        cnn_backbone='resnet50',\n",
    "        deit_model='deit_small_patch16_224',\n",
    "        lora_rank=8,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.1,\n",
    "        freeze_cnn=True\n",
    "    )\n",
    "    \n",
    "    model = validate_and_fix_parameters(model)\n",
    "    \n",
    "    total_params, trainable_params = model.count_parameters()\n",
    "    print(f\"Model created - Total: {total_params:,}, Trainable: {trainable_params:,}\")\n",
    "    print(f\"Parameter efficiency: {(trainable_params/total_params)*100:.2f}%\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"Cleared CUDA cache\")\n",
    "    \n",
    "    print(\"\\n=== Testing on CPU ===\")\n",
    "    cpu_device = torch.device('cpu')\n",
    "    model = safe_move_model_to_device(model, cpu_device)\n",
    "    \n",
    "    try:\n",
    "        dummy_input = torch.randn(2, 3, 224, 224)\n",
    "        with torch.no_grad():\n",
    "            output = model(dummy_input)\n",
    "        print(f\"✓ CPU forward pass successful: {output.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ CPU forward pass failed: {e}\")\n",
    "        return\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"\\n=== Moving to GPU ===\")\n",
    "        gpu_device = torch.device('cuda')\n",
    "        model = safe_move_model_to_device(model, gpu_device)\n",
    "        \n",
    "        try:\n",
    "            dummy_input = torch.randn(2, 3, 224, 224).to(gpu_device)\n",
    "            with torch.no_grad():\n",
    "                output = model(dummy_input)\n",
    "            print(f\"✓ GPU forward pass successful: {output.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ GPU forward pass failed: {e}\")\n",
    "            return\n",
    "    \n",
    "    print(\"Model validation complete!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorchtensorflow)",
   "language": "python",
   "name": "pytorchtensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
